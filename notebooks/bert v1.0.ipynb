{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install torch scikit-learn --quiet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "NUM_SAMPLES = 1000\n",
    "SEQ_LEN = 10\n",
    "NUM_DEPTS = 5\n",
    "EMBED_DIM = 64\n",
    "MASK_PROB = 0.15\n",
    "NUM_SEASONS = 4\n",
    "\n",
    "def generate_synthetic():\n",
    "    dept_seq = torch.randint(0, NUM_DEPTS, (NUM_SAMPLES, SEQ_LEN))\n",
    "    season_ids = torch.randint(0, NUM_SEASONS, (NUM_SAMPLES, SEQ_LEN))\n",
    "\n",
    "    labels = torch.randint(0, 2, (NUM_SAMPLES, NUM_DEPTS)).float()\n",
    "\n",
    "    customer_emb = torch.randn(NUM_SAMPLES, EMBED_DIM)\n",
    "    product_emb = torch.randn(NUM_SAMPLES, SEQ_LEN, EMBED_DIM)\n",
    "    season_emb = torch.randn(NUM_SAMPLES, EMBED_DIM)\n",
    "    weather_emb = torch.randn(NUM_SAMPLES, EMBED_DIM)\n",
    "    promo_emb = torch.randn(NUM_SAMPLES, EMBED_DIM)\n",
    "\n",
    "    return {\n",
    "        \"sequences\": dept_seq,\n",
    "        \"season_ids\": season_ids,\n",
    "        \"labels\": labels,\n",
    "        \"customer_emb\": customer_emb,\n",
    "        \"product_emb\": product_emb,\n",
    "        \"season_emb\": season_emb,\n",
    "        \"weather_emb\": weather_emb,\n",
    "        \"promo_emb\": promo_emb\n",
    "    }\n",
    "\n",
    "data = generate_synthetic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_decay(seq_len, gamma=0.95):\n",
    "    decay = torch.tensor([gamma**i for i in reversed(range(seq_len))], dtype=torch.float)\n",
    "    decay = decay / decay.sum()\n",
    "    return decay.unsqueeze(0)  # [1, T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BERT4Rec(nn.Module):\n",
    "    def __init__(self, vocab_size, num_depts, emb_dim, seq_len, num_seasons):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size + 1, emb_dim, padding_idx=vocab_size)\n",
    "        self.pos_emb = nn.Embedding(seq_len, emb_dim)\n",
    "        self.season_pos_emb = nn.Embedding(num_seasons, emb_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=4, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "\n",
    "        self.struct_proj = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 4, emb_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_depts),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, seqs, season_ids, customer_emb, product_emb, season_emb, weather_emb, promo_emb, decay=None):\n",
    "        B, T = seqs.shape\n",
    "        pos_ids = torch.arange(T, device=seqs.device).unsqueeze(0).expand(B, T)\n",
    "\n",
    "        x = self.token_emb(seqs) + self.season_pos_emb(season_ids) + self.pos_emb(pos_ids)\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        if decay is not None:\n",
    "            x = (x * decay.unsqueeze(-1)).sum(1)  # Weighted sum\n",
    "        else:\n",
    "            x = x[:, 0, :]  # CLS token approach\n",
    "\n",
    "        struct = torch.cat([season_emb, weather_emb, promo_emb, customer_emb], dim=-1)\n",
    "        struct = self.struct_proj(struct)\n",
    "\n",
    "        final = torch.cat([x, struct], dim=-1)\n",
    "        return self.head(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, data, epochs=5, batch_size=32, lr=1e-3, gamma=0.95):\n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "        data[\"sequences\"], data[\"season_ids\"], data[\"labels\"],\n",
    "        data[\"customer_emb\"], data[\"product_emb\"],\n",
    "        data[\"season_emb\"], data[\"weather_emb\"], data[\"promo_emb\"]\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            seqs, season_ids, labels, cust, prod, seas, weath, promo = batch\n",
    "            decay = get_decay(seqs.size(1)).to(seqs.device)\n",
    "\n",
    "            out = model(seqs, season_ids, cust, prod, seas, weath, promo, decay)\n",
    "            loss = loss_fn(out, labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        decay = get_decay(data[\"sequences\"].size(1))\n",
    "        preds = model(\n",
    "            data[\"sequences\"], data[\"season_ids\"],\n",
    "            data[\"customer_emb\"], data[\"product_emb\"],\n",
    "            data[\"season_emb\"], data[\"weather_emb\"],\n",
    "            data[\"promo_emb\"], decay\n",
    "        )\n",
    "        preds_bin = (preds > 0.5).float()\n",
    "        f1 = f1_score(data[\"labels\"].numpy(), preds_bin.numpy(), average=\"macro\")\n",
    "        print(f\"Macro F1 score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 22.2687\n",
      "Epoch 2: Loss = 21.9999\n",
      "Epoch 3: Loss = 21.6070\n",
      "Epoch 4: Loss = 20.7738\n",
      "Epoch 5: Loss = 19.4211\n",
      "Macro F1 score: 0.7786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BERT4Rec(vocab_size=NUM_DEPTS, num_depts=NUM_DEPTS,\n",
    "                 emb_dim=EMBED_DIM, seq_len=SEQ_LEN, num_seasons=NUM_SEASONS)\n",
    "\n",
    "train_model(model, data)\n",
    "evaluate_model(model, data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
